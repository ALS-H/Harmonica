{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fa751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load preprocessed MIDI features\n",
    "with open(\"processed_midi_data.pkl\", \"rb\") as f:\n",
    "    midi_features = pickle.load(f)\n",
    "# Extract feature data\n",
    "tempos = [f[\"tempo\"] for f in midi_features.values()]\n",
    "keys = [f[\"key\"] for f in midi_features.values()]\n",
    "note_densities = [f[\"note_density\"] for f in midi_features.values()]\n",
    "velocities = [f[\"avg_velocity\"] for f in midi_features.values()]\n",
    "\n",
    "print(\"Dataset statistics:\")\n",
    "print(f\"Tempo range: {min(tempos):.1f} to {max(tempos):.1f}, mean: {np.mean(tempos):.1f}\")\n",
    "print(f\"Key range: {min(keys)} to {max(keys)}, mean: {np.mean(keys):.1f}\")\n",
    "print(f\"Note density range: {min(note_densities):.1f} to {max(note_densities):.1f}, mean: {np.mean(note_densities):.1f}\")\n",
    "print(f\"Velocity range: {min(velocities):.1f} to {max(velocities):.1f}, mean: {np.mean(velocities):.1f}\")\n",
    "\n",
    "# Calculate percentiles for each feature\n",
    "tempo_25 = np.percentile(tempos, 25)\n",
    "tempo_50 = np.percentile(tempos, 50)\n",
    "tempo_75 = np.percentile(tempos, 75)\n",
    "\n",
    "note_25 = np.percentile(note_densities, 25)\n",
    "note_50 = np.percentile(note_densities, 50)\n",
    "note_75 = np.percentile(note_densities, 75)\n",
    "\n",
    "vel_25 = np.percentile(velocities, 25)\n",
    "vel_50 = np.percentile(velocities, 50)\n",
    "vel_75 = np.percentile(velocities, 75)\n",
    "\n",
    "print(\"\\nPercentiles:\")\n",
    "print(f\"Tempo 25/50/75: {tempo_25:.1f}/{tempo_50:.1f}/{tempo_75:.1f}\")\n",
    "print(f\"Note density 25/50/75: {note_25:.1f}/{note_50:.1f}/{note_75:.1f}\")\n",
    "print(f\"Velocity 25/50/75: {vel_25:.1f}/{vel_50:.1f}/{vel_75:.1f}\")\n",
    "\n",
    "# Count major vs minor keys\n",
    "major_keys = sum(1 for k in keys if k < 12)\n",
    "minor_keys = sum(1 for k in keys if k >= 12)\n",
    "print(f\"Major keys: {major_keys} ({major_keys/len(keys)*100:.1f}%)\")\n",
    "print(f\"Minor keys: {minor_keys} ({minor_keys/len(keys)*100:.1f}%)\")\n",
    "\n",
    "\n",
    "\n",
    "# Calculate percentiles for each feature\n",
    "tempo_25 = np.percentile(tempos, 25)\n",
    "tempo_50 = np.percentile(tempos, 50)\n",
    "tempo_75 = np.percentile(tempos, 75)\n",
    "\n",
    "note_25 = np.percentile(note_densities, 25)\n",
    "note_50 = np.percentile(note_densities, 50)\n",
    "note_75 = np.percentile(note_densities, 75)\n",
    "\n",
    "vel_25 = np.percentile(velocities, 25)\n",
    "vel_50 = np.percentile(velocities, 50)\n",
    "vel_75 = np.percentile(velocities, 75)\n",
    "\n",
    "# Count major vs minor keys\n",
    "major_keys = sum(1 for k in keys if k < 12)\n",
    "minor_keys = sum(1 for k in keys if k >= 12)\n",
    "\n",
    "# Define emotion mapping based on the actual data distribution\n",
    "emotion_mapping = {\n",
    "    \"Happy\": {\n",
    "        \"tempo\": (tempo_50, max(tempos)),\n",
    "        \"key\": \"major\",\n",
    "        \"note_density\": (note_50, max(note_densities)),\n",
    "        \"velocity\": (vel_50, max(velocities)),\n",
    "        \"weight\": 0.7\n",
    "    },\n",
    "    \"Sad\": {\n",
    "        \"tempo\": (min(tempos), tempo_25),\n",
    "        \"key\": \"minor\",\n",
    "        \"note_density\": (min(note_densities), note_50),\n",
    "        \"velocity\": (min(velocities), vel_25),\n",
    "        \"weight\": 1.2\n",
    "    },\n",
    "    \"Calm\": {\n",
    "        \"tempo\": (min(tempos), tempo_50),\n",
    "        \"key\": \"both\",\n",
    "        \"note_density\": (min(note_densities), note_25),\n",
    "        \"velocity\": (min(velocities), vel_50),\n",
    "        \"weight\": 1.2\n",
    "    },\n",
    "    \"Energetic\": {\n",
    "        \"tempo\": (tempo_75, max(tempos)),\n",
    "        \"key\": \"both\",\n",
    "        \"note_density\": (note_75, max(note_densities)),\n",
    "        \"velocity\": (vel_75, max(velocities)),\n",
    "        \"weight\": 0.65\n",
    "    },\n",
    "    \"Romantic\": {\n",
    "        \"tempo\": (tempo_25, tempo_75),\n",
    "        \"key\": \"both\",\n",
    "        \"note_density\": (note_25, note_75),\n",
    "        \"velocity\": (vel_25, vel_75),\n",
    "        \"weight\": 1.1\n",
    "    },\n",
    "    \"Fearful\": {\n",
    "        \"tempo\": (tempo_25, tempo_75),\n",
    "        \"key\": \"minor\",\n",
    "        \"note_density\": (note_50, max(note_densities)),\n",
    "        \"velocity\": (vel_25, vel_75),\n",
    "        \"weight\": 1.3\n",
    "    },\n",
    "    \"Angry\": {\n",
    "        \"tempo\": (tempo_50, max(tempos)),\n",
    "        \"key\": \"minor\",\n",
    "        \"note_density\": (note_75, max(note_densities)),\n",
    "        \"velocity\": (vel_75, max(velocities)),\n",
    "        \"weight\": 1.2\n",
    "    },\n",
    "    \"Mysterious\": {\n",
    "        \"tempo\": (min(tempos), tempo_50),\n",
    "        \"key\": \"minor\",\n",
    "        \"note_density\": (note_25, note_75),\n",
    "        \"velocity\": (min(velocities), vel_50),\n",
    "        \"weight\": 1.3\n",
    "    }\n",
    "}\n",
    "\n",
    "def classify_emotion_with_fuzzy_membership(features):\n",
    "    \"\"\"\n",
    "    Classify emotion using fuzzy membership functions instead of hard boundaries.\n",
    "    This allows pieces to partially belong to multiple emotion categories.\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    # Get key category\n",
    "    key_category = \"major\" if features[\"key\"] < 12 else \"minor\"\n",
    "    \n",
    "    for emotion, params in emotion_mapping.items():\n",
    "        tempo_range = params[\"tempo\"]\n",
    "        key_type = params[\"key\"]\n",
    "        note_range = params[\"note_density\"]\n",
    "        velocity_range = params[\"velocity\"]\n",
    "        weight = params[\"weight\"]\n",
    "        \n",
    "        # Calculate feature scores using fuzzy membership\n",
    "        \n",
    "        # Tempo score - triangular membership function\n",
    "        if features[\"tempo\"] <= tempo_range[0]:\n",
    "            tempo_score = 0\n",
    "        elif features[\"tempo\"] >= tempo_range[1]:\n",
    "            tempo_score = 0\n",
    "        else:\n",
    "            # Peak at the middle of the range\n",
    "            middle = (tempo_range[0] + tempo_range[1]) / 2\n",
    "            if features[\"tempo\"] <= middle:\n",
    "                tempo_score = (features[\"tempo\"] - tempo_range[0]) / (middle - tempo_range[0])\n",
    "            else:\n",
    "                tempo_score = (tempo_range[1] - features[\"tempo\"]) / (tempo_range[1] - middle)\n",
    "                \n",
    "        # Key score - binary membership\n",
    "        if key_type == \"both\":\n",
    "            key_score = 1.0\n",
    "        elif key_category == key_type:\n",
    "            key_score = 1.0\n",
    "        else:\n",
    "            key_score = 0.0\n",
    "        \n",
    "        # Note density score - triangular membership\n",
    "        if features[\"note_density\"] <= note_range[0]:\n",
    "            note_score = 0\n",
    "        elif features[\"note_density\"] >= note_range[1]:\n",
    "            note_score = 0\n",
    "        else:\n",
    "            middle = (note_range[0] + note_range[1]) / 2\n",
    "            if features[\"note_density\"] <= middle:\n",
    "                note_score = (features[\"note_density\"] - note_range[0]) / (middle - note_range[0])\n",
    "            else:\n",
    "                note_score = (note_range[1] - features[\"note_density\"]) / (note_range[1] - middle)\n",
    "        \n",
    "        # Velocity score - triangular membership\n",
    "        if features[\"avg_velocity\"] <= velocity_range[0]:\n",
    "            velocity_score = 0\n",
    "        elif features[\"avg_velocity\"] >= velocity_range[1]:\n",
    "            velocity_score = 0\n",
    "        else:\n",
    "            middle = (velocity_range[0] + velocity_range[1]) / 2\n",
    "            if features[\"avg_velocity\"] <= middle:\n",
    "                velocity_score = (features[\"avg_velocity\"] - velocity_range[0]) / (middle - velocity_range[0])\n",
    "            else:\n",
    "                velocity_score = (velocity_range[1] - features[\"avg_velocity\"]) / (velocity_range[1] - middle)\n",
    "        \n",
    "        # Calculate weighted score\n",
    "        # Give higher weight to key for emotional impact\n",
    "        feature_weights = {\n",
    "            \"tempo\": 1.2,\n",
    "            \"key\": 1.5,\n",
    "            \"note\": 1.0,\n",
    "            \"velocity\": 1.1\n",
    "        }\n",
    "        \n",
    "        weighted_score = (\n",
    "            tempo_score * feature_weights[\"tempo\"] +\n",
    "            key_score * feature_weights[\"key\"] +\n",
    "            note_score * feature_weights[\"note\"] +\n",
    "            velocity_score * feature_weights[\"velocity\"]\n",
    "        ) * weight\n",
    "        \n",
    "        max_possible = sum(feature_weights.values())\n",
    "        normalized_score = weighted_score / max_possible\n",
    "        \n",
    "        scores[emotion] = normalized_score\n",
    "    \n",
    "    # Find emotion with highest score\n",
    "    best_emotion = max(scores, key=scores.get)\n",
    "    best_score = scores[best_emotion]\n",
    "    \n",
    "    # Return the top emotion, but ensure variety in the dataset\n",
    "    if best_score >= 0.4:\n",
    "        return best_emotion, scores\n",
    "    else:\n",
    "        return \"Unknown\", scores\n",
    "\n",
    "# Process all MIDI files\n",
    "results = {}\n",
    "emotion_scores = {}\n",
    "\n",
    "for file, features in midi_features.items():\n",
    "    emotion, scores = classify_emotion_with_fuzzy_membership(features)\n",
    "    results[file] = emotion\n",
    "    emotion_scores[file] = scores\n",
    "\n",
    "# Create DataFrame\n",
    "emotion_df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Emotion\"])\n",
    "\n",
    "# Check distribution\n",
    "emotion_counts = emotion_df[\"Emotion\"].value_counts()\n",
    "\n",
    "# Balance distribution if needed\n",
    "MAX_PERCENTAGE = 30.0  # Maximum percentage for any emotion\n",
    "for emotion, count in emotion_counts.items():\n",
    "    if count/len(emotion_df)*100 > MAX_PERCENTAGE and emotion != \"Unknown\":\n",
    "        # Find how many files to reassign\n",
    "        excess = int(count - (MAX_PERCENTAGE * len(emotion_df) / 100))\n",
    "        \n",
    "        # Find files with this emotion sorted by lowest score\n",
    "        emotion_files = [file for file, e in results.items() if e == emotion]\n",
    "        emotion_scores_list = [(file, emotion_scores[file][emotion]) for file in emotion_files]\n",
    "        emotion_scores_list.sort(key=lambda x: x[1])  # Sort by score (lowest first)\n",
    "        \n",
    "        # Reassign the lowest scoring files to their second-best emotion\n",
    "        for i in range(excess):\n",
    "            if i < len(emotion_scores_list):\n",
    "                file_to_reassign = emotion_scores_list[i][0]\n",
    "                file_scores = emotion_scores[file_to_reassign]\n",
    "                \n",
    "                # Find second-best emotion\n",
    "                sorted_emotions = sorted(file_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "                second_best = sorted_emotions[1][0]  # Second item in sorted list\n",
    "                \n",
    "                # Reassign if second-best is not Unknown\n",
    "                if second_best != \"Unknown\" and file_scores[second_best] > 0.25:\n",
    "                    results[file_to_reassign] = second_best\n",
    "\n",
    "# Update DataFrame with adjusted results\n",
    "emotion_df = pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Emotion\"])\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"midi_emotion_labels.csv\"\n",
    "print(\"Emotions tagged successfully\")\n",
    "emotion_df.to_csv(output_file)\n",
    "midi_emotion_labels = results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
