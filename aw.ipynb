{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d8490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion Classification Agent\n",
    "class EmotionAgent:\n",
    "    def classify(self, midi_file):\n",
    "        return midi_emotion_labels[midi_file]\n",
    "\n",
    "# Prompt Engineering Agent\n",
    "class PromptEngineeringAgent:\n",
    "    def create_prompt(self, midi_file, emotion):\n",
    "        features = midi_features[midi_file]\n",
    "        return (\n",
    "            f\"A {emotion.lower()} piece of piano music with a tempo of {features['tempo']} BPM, \"\n",
    "            f\"written in {'major' if features['key'] < 12 else 'minor'} key, \"\n",
    "            f\"and an average note density of {features['note_density']} notes per second. \"\n",
    "            f\"It should evoke {emotion.lower()} feelings with expressive melodies.\"\n",
    "        )\n",
    "\n",
    "# Music Generation Agent\n",
    "class MusicGenerationAgent:\n",
    "    def generate(self, prompt, mode=\"cot\", output_filename=\"Agenticgenerated_music.wav\"):\n",
    "        if mode == \"cot\":\n",
    "            return generate_music_CoT(prompt, output_filename)\n",
    "        elif mode == \"got\":\n",
    "            return generate_music_GoT(prompt, output_filename)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode. Choose 'cot' or 'got'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd88e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class AgenticMusicWorkflow:\n",
    "    def __init__(self):\n",
    "        self.emotion_agent = EmotionAgent()\n",
    "        self.prompt_agent = PromptEngineeringAgent()\n",
    "        self.music_agent = MusicGenerationAgent()\n",
    "\n",
    "    def run(self, midi_file, mode=\"cot\"):\n",
    "        print(f\"ðŸŽµ Starting generation for: {midi_file} | Mode: {mode.upper()}\")\n",
    "\n",
    "        emotion = self.emotion_agent.classify(midi_file)\n",
    "        print(f\"[EmotionAgent] âž¤ Classified Emotion: {emotion}\")\n",
    "\n",
    "        prompt = self.prompt_agent.create_prompt(midi_file, emotion)\n",
    "        print(f\"[PromptAgent] âž¤ Generated Prompt:\\n{prompt}\")\n",
    "\n",
    "        # ðŸ’¡ Fix: Sanitize filename to avoid invalid paths\n",
    "        midi_basename = os.path.basename(midi_file).replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "        output_file = f\"{midi_basename}_{mode}_output.wav\"\n",
    "\n",
    "        result_path = self.music_agent.generate(prompt, mode=mode, output_filename=output_file)\n",
    "        print(f\"[MusicAgent] âž¤ Music generated at: {result_path}\")\n",
    "\n",
    "        return result_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4387e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "with open(\"processed_midi_data.pkl\", \"rb\") as f:\n",
    "    midi_features = pickle.load(f)\n",
    "\n",
    "\n",
    "# Load final emotions\n",
    "final_emotion_df = pd.read_csv(\"final_midi_emotion_labels.csv\", index_col=0)\n",
    "final_emotion_labels = final_emotion_df[\"Final Emotion\"].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a84836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the full agentic pipeline\n",
    "workflow = AgenticMusicWorkflow()\n",
    "\n",
    "# Choose any MIDI file key from your features\n",
    "example_midi = list(midi_features.keys())[0]\n",
    "\n",
    "# Run in CoT mode\n",
    "cot_path = workflow.run(example_midi, mode=\"cot\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
